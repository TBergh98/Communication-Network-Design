{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27b8f7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82569c91",
   "metadata": {},
   "source": [
    "# TODO 1: Source Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4e8e42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some auxiliary functions\n",
    "def make_batch(mean_B : float) -> int:\n",
    "    '''\n",
    "    Returns an integer drawn by a geometric distribution with parameter p=1/mean_B.\n",
    "    '''\n",
    "    p = 1/mean_B # \"Success\" probability\n",
    "    B = np.random.geometric(p)\n",
    "    return B\n",
    "\n",
    "def wait_T_off(mean_T_off : float) -> float:\n",
    "    '''\n",
    "    Returns a float number drawn by an exponential distribution with parameter lambda=1/mean_T_off\n",
    "    '''\n",
    "    T_off = np.random.exponential(mean_T_off)\n",
    "    return T_off\n",
    "\n",
    "def gen_VBR_traffic(arr_times, batches, T_on : float, tau : float, mean_B : int, T_off : float) -> None:\n",
    "    '''\n",
    "    Function that generates VBR traffic with the following parameters:\n",
    "    + arr_times: list to store the times of every new batch arrival.\n",
    "    + batches:   list to store the batch sizes at every arrival time.\n",
    "    + T_on:      duration of the ON period.\n",
    "    + tau:       interarrival time during the ON period.\n",
    "    + mean_B:    mean value for the size of a batch.\n",
    "    + T_off:     mean duration of the OFF period\n",
    "    \n",
    "    Returns:\n",
    "    + Updated arr_times list.\n",
    "    + Updated batches list.\n",
    "    '''\n",
    "    # FIRST BATCH ARRIVAL\n",
    "    # At this point arr_times will have one element more than batches, since the information\n",
    "    # about the next arriving packet is given by knowing the duration of T_off.\n",
    "    t_on = 0\n",
    "    batches.append(make_batch(mean_B)) # Batch size of the batch arriving at t_on=0.\n",
    "    \n",
    "    t_on += tau # arrival time of the second batch of the ON period\n",
    "    while t_on <= T_on:\n",
    "        arr_times.append(tau)\n",
    "        batches.append(make_batch(mean_B))\n",
    "        t_on += tau\n",
    "    \n",
    "    # Compute the \"wasted time\" in the ON period\n",
    "    if (T_on/tau).is_integer():\n",
    "        arr_times.append(wait_T_off(T_off))\n",
    "    else:\n",
    "        wasted_time = T_on - (t_on - tau) # Can only be > 0\n",
    "        arr_times.append(wasted_time + wait_T_off(T_off))\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e2274ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate N_c ON/OFF cycles of traffic\n",
    "def source_model(arr_times, batches, T_on, tau, mean_B, T_off, L, Nc):\n",
    "    '''\n",
    "    Extends functioning of the above function to the whole source model\n",
    "    '''\n",
    "    t0 = 0 # Initial Time of the first ON period (w.l.o.g. = 0)\n",
    "    arr_times.append(t0)\n",
    "    \n",
    "    cycle_count = 1\n",
    "    while cycle_count <= Nc:\n",
    "        gen_VBR_traffic(arr_times, batches, T_on, tau, mean_B, T_off)\n",
    "        cycle_count += 1\n",
    "    \n",
    "    # pop last element of the arr_times vector since the last cycle has to be cut off\n",
    "    arr_times.pop()\n",
    "    \n",
    "    # Convert lists in np.array\n",
    "    arr_times = np.array(arr_times)\n",
    "    batches = np.array(batches)\n",
    "    \n",
    "    # Workload vector\n",
    "    workload = np.multiply(batches, L)\n",
    "    return arr_times, batches, workload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "637159e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write matrix in fixed point notation\n",
    "def write_matrix_S(interarr_times, batches, workload, filename='S_matrix.txt'):\n",
    "    '''\n",
    "    Function that take the 3 array generated by source_model and writes a file\n",
    "    with the corresponding matrix S in fixed point notation\n",
    "    '''\n",
    "    # Reshape all the arrays\n",
    "    interarr_times = interarr_times.reshape((-1,1))\n",
    "    batches = batches.reshape((-1,1))\n",
    "    workload = workload.reshape((-1,1))\n",
    "    # Create matrix S (with 3 columns)\n",
    "    S = np.column_stack((interarr_times, batches, workload))\n",
    "    # Fixed point notation\n",
    "    np.set_printoptions(suppress=True, formatter={'float_kind':'{:0.6f}'.format})\n",
    "    S = np.around(S, 6)\n",
    "    # Write on txt file\n",
    "    np.savetxt(filename, S, fmt='%0.6f')\n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab2dd8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final function for the Source Module\n",
    "def source_model_and_S(arr_times, batches, T_on, tau, mean_B, T_off, L, Nc, filename='S_matrix.txt'):\n",
    "    '''\n",
    "    Function that does all the tasks of section 1.1 of the HW Assignment.\n",
    "    It computes interarrival times, batch sizes and workload, and store them in a matrix\n",
    "    S, which is also written in a .txt file in fixed point notation (with 6 digits precision)\n",
    "    '''\n",
    "    arr_times, batches, workload = source_model(arr_times, batches, T_on, tau, mean_B, T_off, L, Nc)\n",
    "    S = write_matrix_S(arr_times, batches, workload, filename)\n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "834fc603",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_times, batches = [], []\n",
    "S = source_model_and_S(arr_times, batches,T_on=1,tau=0.2,mean_B=3,T_off=1,L=1000,Nc=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a995446e",
   "metadata": {},
   "source": [
    "# TODO 2: Token Bucket Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2550fc0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.000000 2.000000 3.000000 4.000000 5.000000 6.000000 7.000000 8.000000\n",
      " 9.000000 10.000000 11.000000 12.000000 13.000000 14.000000 15.000000\n",
      " 16.000000 17.000000 18.000000 19.000000 20.000000 21.000000 22.000000\n",
      " 23.000000 24.000000 26.000000 27.000000 29.000000]\n",
      "[20072 13482  8835  5834  3923  2618  1742  1157   806   521   319   228\n",
      "   159    93    61    46    34    26    16     8     6     5     2     2\n",
      "     2     1     2]\n"
     ]
    }
   ],
   "source": [
    "# Auxiliary Functions\n",
    "def read_matrix_S(fname = 'S_matrix.txt'):\n",
    "    S = np.loadtxt(fname, delimiter=' ')\n",
    "    return S\n",
    "\n",
    "S = read_matrix_S()\n",
    "S = S[:,1]\n",
    "unique, counts = np.unique(S, return_counts=True)\n",
    "print(unique), print(counts)\n",
    "\n",
    "def count_compliant(F : list, S : np.ndarray,  t : int, bt : int):\n",
    "    '''\n",
    "    Function that writes in F a 1 for each compliant pck, and a 0 for each non compliant pck\n",
    "    that occur at a certain arrival event (each row of S).\n",
    "    bt is the number of tokens available at that time.\n",
    "    It also returns the updated bt capacity.\n",
    "    '''\n",
    "    # Extract info corresponding to the t-th row of S\n",
    "    batch_info = S[t,:]\n",
    "    B_i = int(batch_info[1])\n",
    "    W_i = batch_info[2]\n",
    "    \n",
    "    # Extract packet size\n",
    "    L = W_i/B_i\n",
    "    \n",
    "    max_compliant = int(bt//L) # Maximum number of compliant pck given the actual state of the bucket\n",
    "    rem_tokens = bt%L # tokens remaining if max_compliant pcks arrive\n",
    "    \n",
    "    if B_i <= max_compliant: # We are not emptying the bucket\n",
    "        ones = [1] * B_i # ones = [1,1,...] for B_i times\n",
    "        F.extend(ones) # append B_i ones to F\n",
    "        bt = rem_tokens + (max_compliant - B_i)*L # Remaining tokens not exploited by source\n",
    "    \n",
    "    if B_i > max_compliant: # Some packets will be not compliant\n",
    "        ones = [1] * max_compliant\n",
    "        zeros = [0] * (B_i-max_compliant)\n",
    "        F.extend(ones)\n",
    "        F.extend(zeros)\n",
    "        bt = rem_tokens\n",
    "        \n",
    "    return bt\n",
    "\n",
    "def fill_bucket(b_init : int, b, rho, delta_t):\n",
    "    '''\n",
    "    Function that computes the final value of b(t) just before the beginning of a new ON period\n",
    "    '''\n",
    "    bt = b_init + (rho * delta_t)\n",
    "    bt = min(b, bt)\n",
    "    return bt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5180cf22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000.0\n"
     ]
    }
   ],
   "source": [
    "info = S[3,:]\n",
    "print(info[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70a1e9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Function for the TBF module\n",
    "def TBF(b, rho, b0, fname = 'S_matrix.txt'):\n",
    "    S = read_matrix_S(fname)\n",
    "    F = []\n",
    "    bt = b0\n",
    "    for t in range(S.shape[0]-1):\n",
    "        bt = count_compliant(F, S,  t, bt) # written F and bt=remaining tokens\n",
    "        delta_t = S[t+1,0]\n",
    "        bt = fill_bucket(bt, b, rho, delta_t) # fill with tokens in the OFF period\n",
    "    F = np.array(F).reshape((-1,1))\n",
    "    return F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "833e02cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(179355, 1)\n"
     ]
    }
   ],
   "source": [
    "F = TBF(b=3000, rho=8000, b0=3000, fname = 'S_matrix.txt')\n",
    "print(F.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ccaea59",
   "metadata": {},
   "source": [
    "# TODO 3: Empirical Estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93202757",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_prob(F):\n",
    "    unique, freq = np.unique(F, return_counts=True)\n",
    "    freq = np.divide(freq, F.shape[0])\n",
    "    print(f'{unique} have respectively empirical relative frequence of: {freq}')\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8411dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B = np.arange(2000,50000,2000)\n",
    "# print(B.shape)\n",
    "# RHO = np.arange(2000, 50000, 2000)\n",
    "# z = np.zeros((B.shape[0], RHO.shape[0]))\n",
    "\n",
    "# for b in range(B.shape[0]):\n",
    "#     for rho in range(RHO.shape[0]):\n",
    "#         z[m,l] = (1-np.exp(-0.00082*(b+rho)))*np.exp(-b/rho)\n",
    "\n",
    "# MM, LL = np.meshgrid(B, RHO)\n",
    "\n",
    "# fig = plt.figure()\n",
    "# ax = plt.axes(projection=\"3d\")\n",
    "# ax.plot_wireframe(MM, LL, z, color='green')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a22c9b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1] have respectively empirical relative frequence of: [0.133880 0.866120]\n"
     ]
    }
   ],
   "source": [
    "F = TBF(b=5678, rho=28395, b0=5678)\n",
    "estimate_prob(F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "881dc0d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1] have respectively empirical relative frequence of: [0.131917 0.868083]\n"
     ]
    }
   ],
   "source": [
    "F = TBF(b=5678, rho=283900, b0=5678)\n",
    "estimate_prob(F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca52cdc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1] have respectively empirical relative frequence of: [0.461398 0.538602]\n"
     ]
    }
   ],
   "source": [
    "# proposed experiment\n",
    "F = TBF(b=3000, rho=8000, b0=3000)\n",
    "estimate_prob(F)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
